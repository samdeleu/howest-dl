{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cursist: Sam Deleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht Autoencoders\n",
    "\n",
    "\n",
    "Autoencoders zijn neurale netwerken die getraind worden om hun eigen input te reconstrueren. De toepassingen die mogelijk gemaakt worden door autoencoders variÃ«ren van compressie, denoising, reconstructie van afbeeldingen, unsupervised pre-training tot en met one-class classificatie, resolution upscaling, recommendation systems, anomaly detection en image segmentation.\n",
    "\n",
    "Deze opdracht bestaat uit 3 deelopdrachten:\n",
    "1. Anomaly detection\n",
    "2. Denoising \n",
    "3. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    mean_squared_error,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from skimage.metrics import structural_similarity\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Flatten, BatchNormalization,concatenate,\n",
    "    Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "\n",
    "# Some defaults for matplotlib\n",
    "LARGE = 12\n",
    "MEDIUM = 10\n",
    "SMALL = 6\n",
    "plt.tight_layout()\n",
    "plt.rcParams.update({\n",
    "    'legend.fontsize': SMALL,\n",
    "    'figure.figsize': (5, 3),\n",
    "    'axes.labelsize': SMALL,\n",
    "    'axes.titlesize': SMALL,\n",
    "    'xtick.labelsize': SMALL,\n",
    "    'ytick.labelsize': SMALL,\n",
    "    'figure.titlesize': LARGE\n",
    "})\n",
    "# Voor GPU support\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display Helpers\n",
    "def display_title(title, value=None):\n",
    "    if value is None:\n",
    "        cprint(title, \"black\", \"on_cyan\")\n",
    "    else:\n",
    "        print(colored(title, \"blue\"))\n",
    "        print(value)\n",
    "\n",
    "def display_value(title, value):\n",
    "    print(f\"{colored(title, \"blue\")}: {value}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fraude detectie\n",
    "\n",
    "Een anomalie is een datapunt dat qua statistische eigenschappen sterk afwijkt van de meerderheid van de datapunten. Zo kunnen ook frauduleuze banktransacties aanzien worden als anomalieÃ«n.\n",
    "Een van de grootste uitdagingen bij het detecteren van anomaliÃ«n is de ongebalanceerdheid van de data. Deze anomalieÃ«n komen per definitie vrij uitzonderlijk voor. \n",
    "\n",
    "Een mogelijke benadering voor het detecteren van anomalieÃ«n is leren van de distributie van normale datapunten, in dit geval normale banktransacties. Vervolgens kan je nieuwe datapunten classificeren als anomalieÃ«n wanneer ze volgens de geleerde distributie heel onwaarschijnlijk zijn.\n",
    "\n",
    "Autoencoders kunnen de distributie van de normale datapunten leren door deze normale datapunten te leren reconstrueren. De getrainde autoencoder zal vervolgens moeite hebben om anamalieÃ«n te reconstrueren met als resultaat een hoge reconstructie-error, bijvoorbeeld de MSE = Mean Squared Error. https://keras.io/losses/\n",
    "\n",
    "ð‘€ð‘†ð¸=ð‘–ð‘›âˆ‘ð‘›ð‘–=1(ð‘Œâˆ’ð‘ŒÌ‚ )2\n",
    "\n",
    "Een transactie kan dus als frauduleus verondersteld worden wanneer de reconstructie-error boven een zekere threshold uitsteekt. \n",
    "Men spreekt van een one-class classifier.\n",
    "\n",
    "\n",
    "Gegeven is een dataset met banktransacties. Bepaalde features zijn geanonimiseerd (aangeduid met V). Andere features duiden het bedrag en het tijdstip aan. Alle transacties kregen het label 1 (frauduleus) of 0 (normale transactie).\n",
    "\n",
    "\n",
    "\n",
    "Doorloop de volgende stappen:\n",
    "\n",
    "- Controleer in welke mate de dataset gebalanceerd is.\n",
    "\n",
    "- Preprocessing.\n",
    "\n",
    "- Opbouwen van een training set en test set.\n",
    "\n",
    "- Train de autoencoder.\n",
    "\n",
    "- Gebruik de classificatie-error om een transactie te classificeren als normaal of frauduleus.\n",
    "\n",
    "- Test de autoencoder op de test set.\n",
    "\n",
    "- Voer hyperparameter tuning uit op het neuraal netwerk, maar zoek ook een gepaste waarde voor de threshold op de reconstructie error. \n",
    "\n",
    "- Beantwoord de vragen.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "creditcard_input_dataset = pd.read_csv('creditcard.csv')\n",
    "creditcard_input_dataset.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "creditcard_input_dataset.describe().transpose().sort_values(\"std\", ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse van de dataset\n",
    "\n",
    "- Controleer in welke mate de dataset ongebalanceerd is. Maak daarvoor een histogram van de klasselabels. Een geschikte plot is de seaborn countplot (https://seaborn.pydata.org/generated/seaborn.countplot.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyse van de dataset\n",
    "plt.figure(figsize=(6, 4))\n",
    "x = creditcard_input_dataset[\"Class\"].value_counts()\n",
    "display_title(\"Verdeling\", x)\n",
    "sns.countplot(creditcard_input_dataset, x=\"Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Kijken of er null-values zijn\n",
    "creditcard_input_dataset.info()\n",
    "creditcard_input_dataset.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "# Omdat de waarden reeds vanuit een PCA komen is het niet waarschijnlijk dat er verbanden zullen zijn.\n",
    "f, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.heatmap(\n",
    "    creditcard_input_dataset.corr(method='pearson'),\n",
    "    # mask=mask,\n",
    "    cmap=sns.diverging_palette(220, 20, s=100.0, sep=10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\":8}\n",
    ")\n",
    "plt.suptitle('Correlatie Heatmap: full dataset')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Lineaire correlatie tussen de features - heatmap\n",
    "# \n",
    "# Selectie van eventueel te verwijderen features\n",
    "f, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.heatmap(\n",
    "    creditcard_input_dataset[[\"V2\", \"V6\", \"V7\", \"V21\", \"Class\", \"Amount\"]].corr(method='pearson'),\n",
    "    # mask=mask,\n",
    "    cmap=sns.diverging_palette(220, 20, s=100.0, sep=10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\":8}\n",
    ")\n",
    "plt.suptitle('Correlatie Heatmap: partial dataset')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# creditcard_dataset.plot.hist(bins=20)\n",
    "creditcard_input_dataset.hist(bins=50, xlabelsize=8, ylabelsize=8, layout=(8, 4), figsize=(10, 10), color=\"r\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Kuis de dataset op. Verwijder de irrelevante features.\n",
    "- Splits op in een trainig set en test set. Zorg ervoor dat je een gebalanceerde test set bekomt. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verwijderen van de \"Time\" variable\n",
    "# Deze geeft een tijdslijn aan tussen transacties en zal eerder een negatieve invloed hebben op het reconstrueren van transactie\n",
    "# Een alternatief zou kunnen zijn om de tijd te herberekenen op een \"uur van de dag\"\n",
    "creditcard_dataset = creditcard_input_dataset.drop([\"Time\"], axis=1)\n",
    "display(creditcard_dataset.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Normalisatie van de data\n",
    "# Alle waarden worden genormaliseerd om waarden tussen 0 en 1 te krijgen.\n",
    "# We kunnen de Class hierin meenemen omdat die toch 0 of 1 is\n",
    "scaler = MinMaxScaler().fit(creditcard_dataset)\n",
    "creditcard_scaled_input_n = scaler.transform(creditcard_dataset)\n",
    "creditcard_scaled_input_df = pd.DataFrame(creditcard_scaled_input_n, columns = creditcard_dataset.columns)\n",
    "creditcard_scaled_input_df.hist(bins=50, xlabelsize=8, ylabelsize=8, layout=(8, 4), figsize=(10, 10), color=\"r\")\n",
    "\n",
    "display_title(\"Unique values for 'Class' before\", creditcard_scaled_input_df[\"Class\"].value_counts())\n",
    "# display_value(\"Unique values for 'Class'\", creditcard_scaled_input_df[\"Class\"].unique(), creditcard_scaled_input_df[\"Class\"].value_counts())\n",
    "# We zetten de \"Class\" terug in het net\n",
    "creditcard_scaled_input_df[\"Class\"] = (creditcard_scaled_input_df[\"Class\"] >= 0.7).astype(int)\n",
    "display_title(\"Unique values for 'Class' after\", creditcard_scaled_input_df[\"Class\"].value_counts())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Creeer een train en een test-set\n",
    "GOOD_transactions = creditcard_scaled_input_df[creditcard_scaled_input_df[\"Class\"] == 0]\n",
    "FRAUD_transactions = creditcard_scaled_input_df[creditcard_scaled_input_df[\"Class\"] == 1]\n",
    "display_value(\"creditcard_scaled_input_df.shape\", creditcard_scaled_input_df.shape)\n",
    "display_value(\"GOOD_transactions.shape\", GOOD_transactions.shape)\n",
    "display_value(\"FRAUD_transactions.shape\", FRAUD_transactions.shape)\n",
    "\n",
    "# Hierbij neem is een sample van de normale transacties die even groot is als een veelvoud van de frauduleuze transacties.\n",
    "REPEAT_FRAUD_SET = 2\n",
    "\n",
    "test_GOOD_transactions = GOOD_transactions.sample(REPEAT_FRAUD_SET * FRAUD_transactions.shape[0], random_state=42)\n",
    "train_GOOD_transactions = GOOD_transactions.drop(test_GOOD_transactions.index)\n",
    "display_value(\"test_GOOD_transactions.shape\", test_GOOD_transactions.shape)\n",
    "display_value(\"train_GOOD_transactions.shape\", train_GOOD_transactions.shape)\n",
    "\n",
    "test_FRAUD_transactions = pd.concat([FRAUD_transactions] * REPEAT_FRAUD_SET, axis=0, ignore_index=True)\n",
    "test_transactions = pd.concat([test_GOOD_transactions, test_FRAUD_transactions], axis=0, ignore_index=True)\n",
    "display_value(\"test_transactions.shape\", test_transactions.shape)\n",
    "\n",
    "# Remove the \"Class\" feature from the inputs\n",
    "X_train_transactions = train_GOOD_transactions.drop(\"Class\", axis=1)\n",
    "y_train_transactions = train_GOOD_transactions[\"Class\"]\n",
    "display(X_train_transactions.head())\n",
    "display(y_train_transactions.head().values)\n",
    "\n",
    "X_test_transactions = test_transactions.drop(\"Class\", axis=1)\n",
    "y_test_transactions = test_transactions[\"Class\"]\n",
    "display(X_test_transactions.tail())\n",
    "display(y_test_transactions.tail().values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "creditcard_scaled_input_df.iloc[[43428]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Normalisatie van de data\n",
    "X_good_transactions = creditcard_scaled_input_df[creditcard_scaled_input_df[\"Class\"] == 0]\n",
    "X_fraud_transaction = creditcard_scaled_input_df[creditcard_scaled_input_df[\"Class\"] == 1]\n",
    "display(creditcard_scaled_input_df.shape, creditcard_scaled_input_df.shape[1])\n",
    "display(X_good_transactions.shape)\n",
    "display(X_fraud_transaction.shape)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_fraud_transaction.hist(bins=50, xlabelsize=8, ylabelsize=8, layout=(8, 4), figsize=(10, 10), color=\"r\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontwerpen, trainen en hyperparameter tuning v.d. autoencoder\n",
    "\n",
    "- Ontwerp en train een autoencoder. Gebruik de MSE (Mean Squared Error) loss function. Kies zelf de grootte van het neurale netwerk. Deze kan je later bij de hyperparametertuning nog aanpassen.\n",
    "- Kies een threshold voor de MSE waarmee je beslist of een transactie al dan niet frauduleus is.\n",
    "- Gebruik de test set om de autoencoder te evalueren. Gebruik hiervoor de accuraatheid, confusion matrix, recall, precision, f1-score en de ROC.\n",
    "- Voer hyperparameter tuning uit om de performantie te verhogen. Zoek de optimale MSE threshold. Visualeer welke punten boven de threshold liggen en welke eronder. Gebruik kleur om de verschillende klasses aan te duiden.\n",
    "- Stel dat de bank zoveel mogelijk false-negatives (frauduleuze transacties die als normaal werden geclassificeerd) wil vermijden. Welke aanpassingen zou je daarvoor kunnen doen? Test deze."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Ontwerp en training van de autoencoder\n",
    "\n",
    "# Input Layer\n",
    "INPUT_LAYER_SIZE = X_train_transactions.shape[1]\n",
    "CODE_LAYER_SIZE = 4    # 1, 2, 4, 6, 8 geprobeerd voor undercomplete\n",
    "                       # 20, 100, 500 geprobeerd voor overcomplete\n",
    "input_layer = Input(shape =(INPUT_LAYER_SIZE,)) \n",
    "code_layer = Input(shape=(CODE_LAYER_SIZE,))\n",
    "\n",
    "# 1. Het Encoder gedeelte (functional)  (met regularisatie)\n",
    "def encoder_net_1(input_x):\n",
    "    encoder_l1 = Dense(16, activation ='relu', \n",
    "                       activity_regularizer = regularizers.l1(10e-5))(input_x) \n",
    "    encoder_l2 = Dense(8, activation ='relu', \n",
    "                       activity_regularizer = regularizers.l1(10e-5))(encoder_l1) \n",
    "    encoded = Dense(CODE_LAYER_SIZE, activation ='relu')(encoder_l2) \n",
    "    return encoded\n",
    "\n",
    "# Het decoder gedeelte (met regularisatie)\n",
    "def decoder_net_1(encoded_x):\n",
    "    decoder_l1 = Dense(8, activation ='relu', \n",
    "                       activity_regularizer = regularizers.l1(10e-5))(encoded_x) \n",
    "    decoder_l2 = Dense(16, activation ='relu', \n",
    "                       activity_regularizer = regularizers.l1(10e-5))(decoder_l1) \n",
    "    decoded = Dense(INPUT_LAYER_SIZE, activation='sigmoid')(decoder_l2)\n",
    "    return decoded\n",
    "\n",
    "# 2. Zonder regularisatie\n",
    "def encoder_net_2(input_x):\n",
    "    encoder_l1 = Dense(16, activation ='relu')(input_x) \n",
    "    encoder_l2 = Dense(8, activation ='relu')(encoder_l1) \n",
    "    encoded = Dense(CODE_LAYER_SIZE, activation ='relu')(encoder_l2) \n",
    "    return encoded\n",
    "\n",
    "def decoder_net_2(encoded_x):\n",
    "    decoder_l1 = Dense(8, activation ='relu')(encoded_x) \n",
    "    decoder_l2 = Dense(16, activation ='relu')(decoder_l1) \n",
    "    decoded = Dense(INPUT_LAYER_SIZE, activation='sigmoid')(decoder_l2)\n",
    "    return decoded\n",
    "\n",
    "encoder = Model(inputs=input_layer, outputs=encoder_net_1(input_layer))\n",
    "encoder.summary(expand_nested=True, show_trainable=True)\n",
    "decoder = Model(inputs=code_layer, outputs=decoder_net_1(code_layer))\n",
    "decoder.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "total_fraud_autoencoder = Model(inputs=input_layer, outputs=decoder(encoder(input_layer)))\n",
    "total_fraud_autoencoder.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# total_fraud_autoencoder.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     metrics=[keras.metrics.RootMeanSquaredError(name=\"MSE\")],\n",
    "# )\n",
    "\n",
    "# total_fraud_autoencoder.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"mean_squared_error\",\n",
    "#     metrics=[keras.metrics.RootMeanSquaredError(name=\"MSE\")],\n",
    "# )\n",
    "\n",
    "# total_fraud_autoencoder.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\n",
    "#         keras.metrics.RootMeanSquaredError(name=\"MSE\"),\n",
    "#         keras.metrics.CategoricalCrossentropy(name=\"categorical_crossentropy\")\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "total_fraud_autoencoder.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "        keras.metrics.RootMeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "        keras.metrics.CategoricalCrossentropy(name=\"Categorical_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Trainen van de autoencoder for normal transactions\n",
    "EPOCHS = 500\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"loss\",           # metric to monitor\n",
    "    patience=3,               # stop when no improvement after 10 consecutive epochs\n",
    "    mode=\"min\",               # stop when metric stops decreasing\n",
    "    restore_best_weights=True,\n",
    "    verbose=True,             # display the actions taken\n",
    ")\n",
    "history = total_fraud_autoencoder.fit(\n",
    "    X_train_transactions, X_train_transactions,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(history.epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot het verloop van de metrics gedurende de training\n",
    "history_df = pd.DataFrame(history.history)[[\"MSE\", \"val_MSE\", \"loss\", \"val_loss\", \"Binary_Crossentropy\", \"val_Binary_Crossentropy\"]]\n",
    "history_df.plot(\n",
    "    kind=\"line\",\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, len(history.epoch)+2], grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    # style=[\"r--\", \"g--\", \"b--\", \"y--\"])\n",
    "    style={\n",
    "        \"MSE\": \"r-\", \"val_MSE\": \"r--\",\n",
    "        \"loss\": \"b-\", \"val_loss\": \"b--\",\n",
    "        \"Binary_Crossentropy\": \"y-\", \"val_Binary_Crossentropy\": \"y--+\",\n",
    "    }\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot het verloop van de metrics gedurende de training\n",
    "# Dit brengt niets bij en diende alleen ter illustratie van het feit dat categorical crossentropy geen zin heeft\n",
    "history_df = pd.DataFrame(history.history)[[\"Categorical_Crossentropy\", \"val_Categorical_Crossentropy\"]]\n",
    "history_df.plot(\n",
    "    kind=\"line\",\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, len(history.epoch)+2], grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    # style=[\"r--\", \"g--\", \"b--\", \"y--\"])\n",
    "    style={\n",
    "        \"MSE\": \"r-\", \"val_MSE\": \"r--\",\n",
    "        \"loss\": \"b-\", \"val_loss\": \"b--\",\n",
    "        \"Binary_Crossentropy\": \"y-\", \"val_Binary_Crossentropy\": \"y--+\",\n",
    "        \"Categorical_Crossentropy\": \"g-\", \"val_Categorical_Crossentropy\": \"g--+\"\n",
    "    }\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Testen van de autoencoder\n",
    "SAMPLE_SIZE = 2\n",
    "# \n",
    "display_title(\"Resultaten op 1 goede transactie\")\n",
    "selected_good_transaction = X_train_transactions[:SAMPLE_SIZE]\n",
    "display(type(selected_good_transaction))\n",
    "display(selected_good_transaction)\n",
    "display(selected_good_transaction.values)\n",
    "code_good = encoder.predict(selected_good_transaction)\n",
    "display_value(\"Code layer output shape\", code_good.shape)\n",
    "display_value(f\"Good Transactions codes ({type(code_good)})\", f\"\\n{code_good}\")\n",
    "reconstructed_good = decoder.predict(code_good)\n",
    "display(pd.DataFrame(reconstructed_good, columns = selected_good_transaction.columns))\n",
    "\n",
    "# De reconstruction-error (MSE) voor de goede transactie\n",
    "mse_good = np.mean(np.power(selected_good_transaction.values - reconstructed_good, 2), axis=1)\n",
    "display_value(\"MSE (good entry)\", mse_good)\n",
    "# sk_mse_good = metrics.mean_squared_error(selected_good_transaction.values, reconstructed_good, multioutput=\"raw_values\")\n",
    "# display_value(\"sklearn.MSE (good entry)\", sk_mse_good)\n",
    "\n",
    "display_title(\"Resultaten op 1 frauduleuze transactie\")\n",
    "selected_fraud_transaction = test_FRAUD_transactions[:SAMPLE_SIZE].drop(\"Class\", axis=1)\n",
    "display(type(selected_fraud_transaction))\n",
    "display(selected_fraud_transaction)\n",
    "display(selected_fraud_transaction.values)\n",
    "code_fraud = encoder.predict(selected_fraud_transaction)\n",
    "display_value(\"Code layer output shape\", code_fraud.shape)\n",
    "display_value(f\"Fraud Transactions codes ({type(code_fraud)})\", f\"\\n{code_fraud}\")\n",
    "reconstructed_fraud = decoder.predict(code_fraud)\n",
    "display(pd.DataFrame(reconstructed_fraud, columns = selected_fraud_transaction.columns))\n",
    "\n",
    "# De reconstruction-error (MSE) voor de goede transactie\n",
    "mse_fraud = np.mean(np.power(selected_fraud_transaction.values - reconstructed_fraud, 2), axis=1)\n",
    "display_value(\"MSE (fraud entry)\", mse_fraud)\n",
    "# sk_mse_fraud = metrics.mean_squared_error(selected_fraud_transaction.values, reconstructed_fraud, multioutput=\"raw_values\")\n",
    "# display_value(\"sklearn.MSE (fraud entry)\", sk_mse_fraud)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Metrics op training set\n",
    "# Reconstruction error (Mean Squared Error)\n",
    "display_title(\"Evaluation TRAINING set\")\n",
    "reconstructed_train_transactions = total_fraud_autoencoder.predict(X_train_transactions)\n",
    "# display(type(reconstructed_train_transactions))\n",
    "reconstruction_error_training = np.mean(np.power(X_train_transactions.values - reconstructed_train_transactions, 2), axis=1)\n",
    "display_value(\"MSE Training Set\", reconstruction_error_training)\n",
    "display_value(\"Laagste MSE op training\", np.min(reconstruction_error_training))\n",
    "display_value(\"Hoogste MSE op training\", np.max(reconstruction_error_training))\n",
    "\n",
    "# Kies een waarde zodat de meeste goede goed geklasseerd zijn\n",
    "threshold_train = np.percentile(reconstruction_error_training, 95) \n",
    "display_value(\"threshold_train\", threshold_train)\n",
    "\n",
    "y_train_predict = [1 if err > threshold_train else 0 for err in reconstruction_error_training]\n",
    "display_title(\"classification report\", classification_report(y_train_transactions, y_train_predict, zero_division=1.0))\n",
    "display_title(\"confusion matrix\", confusion_matrix(y_train_transactions, y_train_predict))\n",
    "display_value(\"Accuracy score\", (accuracy_score(y_train_transactions, y_train_predict) * 100))\n",
    "display(\"    p0 p1\")\n",
    "display(\"a0: TN FP\")\n",
    "display(\"a1: FN TP\")\n",
    "\n",
    "display_value(\"MSE Threshold\", threshold_train)\n",
    "pd.DataFrame(reconstruction_error_training).hist(bins=3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Metrics op test set\n",
    "# Reconstruction error (Mean Squared Error)\n",
    "display_title(\"Evaluation TEST set\")\n",
    "display_value(\"CODE_LAYER neurons\", CODE_LAYER_SIZE)\n",
    "reconstructed_test_transactions = total_fraud_autoencoder.predict(X_test_transactions)\n",
    "# display(type(reconstructed_test_transactions))\n",
    "reconstruction_error_test = np.mean(np.power(X_test_transactions.values - reconstructed_test_transactions, 2), axis=1)\n",
    "display_value(\"MSE Test Set\", reconstruction_error_test)\n",
    "display_value(\"Laagste MSE op test\", np.min(reconstruction_error_test))\n",
    "display_value(\"Hoogste MSE op test\", np.max(reconstruction_error_test))\n",
    "\n",
    "# Bepaal de classificatie aan de hand van de voorgaande threshold\n",
    "y_test_predict = [1 if err > threshold_train else 0 for err in reconstruction_error_test]\n",
    "display_title(\"classification report\", classification_report(y_test_transactions, y_test_predict, zero_division=\"warn\"))\n",
    "display_title(\"confusion matrix\", confusion_matrix(y_test_transactions, y_test_predict))\n",
    "display_value(\"Accuracy score\", (accuracy_score(y_test_transactions, y_test_predict) * 100))\n",
    "display(\"    p0 p1\")\n",
    "display(\"a0: TN FP\")\n",
    "display(\"a1: FN TP\")\n",
    "\n",
    "display_value(\"MSE Threshold\", threshold_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "threshold = np.percentile(reconstruction_error, 15)\n",
    "display(threshold)\n",
    "y_pred = [1 if e > threshold else 0 for e in reconstruction_error]\n",
    "display(sum(y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning. Zoek naar de optimale waarde voor de MSE-threshold\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Vermijden van false negatives.\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beantwoord de onderstaande vragen\n",
    "ANTWOORDEN:\n",
    "\n",
    "-  Welk type autoencoder is het meest geschikt (undercomplete, overcomplete, convolutional, ...)? Waarom?\n",
    "\n",
    "   Het lijkt erop dat een undercomplete (met in dit geval 4 neuronen in de code layer de betere optie is. Het lijkt erop dat minder neuronen trachten een soort globaal patroon zoeken, terwijl een teveel aan neuronen eerder naar verbanden (interpoleerbaar) zoekt tussen de verschillende features. Ik denk dat daardoor bij undercomplete een soort \"globale eigenschap\" wordt gevonden die eigen is aan een goede transactie en die minder voorkomt in frauduleuze transacties.\n",
    "\n",
    "- Zou het zinvol zijn om de categorical cross-entropy te gebruiken als loss functie?\n",
    "\n",
    "  Gezien het feit dat categorical cross-entropy in samenspel met softmax probeert een waarde te genereren die afhangt van alle features druist dit in tegen het idee dat men een zo exact mogelijke replica van de input wil hebben. Men ziet in de grafiek dat deze verspringt zonder te convergeren naar lagere waarden.\n",
    "\n",
    "- Plot een histogram van de MSE waarden op de training set. Hoe zijn deze verdeeld? Kan je hieruit een schatting maken van waar de threshold zal komen te liggen?\n",
    "\n",
    "  Op de plot van de MSE waarden op de training set zien we een grote groep zeer lage waarden van MSE met een aantal uitschieters. Daarom heb ik geopteerd om met percentiles te werken om een threshold te krijgen die zoveel mogelijk goede transacties omvat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusies\n",
    "\n",
    "### Preprocessing\n",
    "- dataset is heel duidelijk niet gebalanceerd\n",
    "\n",
    "- geen noemenswaardige correlaties tussen verschillende features (eventueel V4 en Amount: 0.4), waarschijnlijk omdat de data reeds het product is van een PCA\n",
    "\n",
    "- de Time variable heeft volgens mij geen significante meerwaarde als we een autoencoder willen gebruiken voor de classificatie.\n",
    "  Deze geeft een tijdslijn aan tussen transacties en zal eerder een negatieve invloed hebben op het reconstrueren van een transactie\n",
    "  Een alternatief zou kunnen zijn om de tijd te herberekenen op een \"uur van de dag\". Hierdoor zou de reconstructie toch rekening kunnen houden met de tijd, maar niet met de sequentie in tijd.\n",
    "\n",
    "- data bevat geen null values en kan volledig worden gebruikt\n",
    "\n",
    "### Train\n",
    "- De training set bevat alleen \"goede\" transacties.\n",
    "  De bedoeling is een zo goed mogelijke reconstructie van goede transacties te kunnen maken.\n",
    "  Als vervolgens een \"frauduleuze\" transactie wordt aangeboden, wordt verwacht dat de reconstructie slecht of liefst zeer slecht is zodat die in het oog springt.\n",
    "\n",
    "- Als loss functie werd geÃ«xperimenteerd met \"mean-squared-error\" en \"binary-crossentropy\".\n",
    "  Ter illustratie van de bovenstaande vraag werd de categorical-crossentropy ook even geprobeerd en uitgezet in grafiek.\n",
    "\n",
    "- Een bedenking die ik echter niet verder heb uitgewerkt: kan er iets worden gedaan met de kennis die men heeft van de frauduleuze transacties?\n",
    "  Hiermee bedoel ik de latente waarden te berekenen van de reconstructie van frauduleuze transacties en dan een combinatie van die kennis met deze van de goede transacties te gebruiken in de predictie.\n",
    " \n",
    "### Test\n",
    "- De test set bevat alle frauduleuze transacties + een even grote sample van de \"goede\" transacties.\n",
    "  Door de test-set te balanceren denk ik dat de metrieken om het model te evalueren beter te interpreteren zijn.\n",
    "   \n",
    "- Deze sample is uit de training set gehaald en worden niet gebruikt tijdens training\n",
    "- De grootte van de testset wordt bepaald door 1 of meerdere keren de frauduleuze transacties te gebruiken (de training set wordt hierdood kleiner)\n",
    "\n",
    "- Om de classificatie uit te voeren wordt terug gekeken naar de MSE\n",
    "\n",
    "### Evaluatie\n",
    "- De undercomplete AE met 4 neurons in de code layer en  zonder regularisatie blijkt het best te werken als men snelheid erbij neemt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enkele resultaten van runs\n",
    "#### Undercomplete Autoencoder without Regularisation\n",
    "\n",
    "```\n",
    "Epochs: 85\n",
    "\n",
    "Evaluation TRAINING set\n",
    "CODE_LAYER neurons: 4\n",
    "\n",
    "8855/8855 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8s 854us/step\n",
    "MSE Training Set: [0.00067703 0.00065632 0.00281367 ... 0.00062344 0.00351914 0.00041329]\n",
    "Laagste MSE op training: 8.635496586405845e-05\n",
    "Hoogste MSE op training: 0.21066324832145344\n",
    "threshold_train: 0.0026070588028623484\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.95      0.97    283331\n",
    "           1       0.00      1.00      0.00         0\n",
    "\n",
    "    accuracy                           0.95    283331\n",
    "   macro avg       0.50      0.97      0.49    283331\n",
    "weighted avg       1.00      0.95      0.97    283331\n",
    "\n",
    "confusion matrix\n",
    "[[269164  14167]\n",
    " [     0      0]]\n",
    "Accuracy score: 94.99984117516262\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0026070588028623484\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "```\n",
    "Evaluation TEST set\n",
    "CODE_LAYER neurons: 4\n",
    "\n",
    "62/62 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 2ms/step\n",
    "MSE Test Set: [0.00051928 0.00047291 0.00179359 ... 0.00284759 0.00596696 0.00087439]\n",
    "Laagste MSE op test: 0.00010933892359824186\n",
    "Hoogste MSE op test: 0.08298927929209654\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.97      0.92       984\n",
    "           1       0.96      0.87      0.92       984\n",
    "\n",
    "    accuracy                           0.92      1968\n",
    "   macro avg       0.92      0.92      0.92      1968\n",
    "weighted avg       0.92      0.92      0.92      1968\n",
    "\n",
    "confusion matrix\n",
    "[[951  33]\n",
    " [126 858]]\n",
    "Accuracy score: 91.92073170731707\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0026070588028623484\n",
    "```\n",
    "\n",
    "==============================================================================\n",
    "\n",
    "#### Undercomplete Autoencoder with L1 Regularisation\n",
    "\n",
    "```\n",
    "Epochs: 32\n",
    "\n",
    "Evaluation TRAINING set\n",
    "CODE_LAYER neurons: 4\n",
    "8855/8855 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 912us/step\n",
    "MSE Training Set: [0.00095919 0.00062705 0.00311123 ... 0.00098528 0.00391642 0.00093597]\n",
    "Laagste MSE op training: 0.0002399110415845007\n",
    "Hoogste MSE op training: 0.26965057099146383\n",
    "threshold_train: 0.0035181321353590983\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.95      0.97    283331\n",
    "           1       0.00      1.00      0.00         0\n",
    "\n",
    "    accuracy                           0.95    283331\n",
    "   macro avg       0.50      0.97      0.49    283331\n",
    "weighted avg       1.00      0.95      0.97    283331\n",
    "\n",
    "confusion matrix\n",
    "[[269164  14167]\n",
    " [     0      0]]\n",
    "Accuracy score: 94.99984117516262\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0035181321353590983\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "```\n",
    "Evaluation TEST set\n",
    "CODE_LAYER neurons: 4\n",
    "\n",
    "62/62 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 8ms/step\n",
    "MSE Test Set: [0.00057391 0.00061873 0.00218368 ... 0.00304568 0.00632093 0.00111598]\n",
    "Laagste MSE op test: 0.00031542728071624014\n",
    "Hoogste MSE op test: 0.08413368495926093\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.96      0.91       984\n",
    "           1       0.95      0.85      0.90       984\n",
    "\n",
    "    accuracy                           0.90      1968\n",
    "   macro avg       0.91      0.90      0.90      1968\n",
    "weighted avg       0.91      0.90      0.90      1968\n",
    "\n",
    "confusion matrix\n",
    "[[942  42]\n",
    " [150 834]]\n",
    "Accuracy score: 90.2439024390244\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0035181321353590983\n",
    "```\n",
    "\n",
    "==============================================================================\n",
    "#### Undercomplete Autoencoder without Regularisation bigger code layer\n",
    "\n",
    "```\n",
    "Epochs: 100+\n",
    "\n",
    "Evaluation TRAINING set\n",
    "CODE_LAYER neurons: 6\n",
    "\n",
    "8855/8855 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8s 835us/step\n",
    "MSE Training Set: [0.0002808  0.0003062  0.0010412  ... 0.00047923 0.0008016  0.00031004]\n",
    "Laagste MSE op training: 4.146281153963198e-05\n",
    "Hoogste MSE op training: 0.1949026639163019\n",
    "threshold_train: 0.0016981010640722827\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.95      0.97    283331\n",
    "           1       0.00      1.00      0.00         0\n",
    "\n",
    "    accuracy                           0.95    283331\n",
    "   macro avg       0.50      0.97      0.49    283331\n",
    "weighted avg       1.00      0.95      0.97    283331\n",
    "\n",
    "confusion matrix\n",
    "[[269164  14167]\n",
    " [     0      0]]\n",
    "Accuracy score: 94.99984117516262\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0016981010640722827\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "```\n",
    "Evaluation TEST set\n",
    "CODE_LAYER neurons: 6\n",
    "\n",
    "62/62 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 7ms/step\n",
    "MSE Test Set: [0.00026625 0.00035952 0.00121059 ... 0.00299825 0.00615299 0.00063766]\n",
    "Laagste MSE op test: 8.629190568271519e-05\n",
    "Hoogste MSE op test: 0.0789094281486494\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.95      0.92       984\n",
    "           1       0.95      0.88      0.91       984\n",
    "\n",
    "    accuracy                           0.92      1968\n",
    "   macro avg       0.92      0.92      0.92      1968\n",
    "weighted avg       0.92      0.92      0.92      1968\n",
    "\n",
    "confusion matrix\n",
    "[[935  49]\n",
    " [116 868]]\n",
    "Accuracy score: 91.61585365853658\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0016981010640722827\n",
    "```\n",
    "\n",
    "==============================================================================\n",
    "\n",
    "#### Overcomplete Autoencoder with Regularisation\n",
    "\n",
    "```\n",
    "Epochs: 26\n",
    "\n",
    "MSE Training Set: [0.0009541  0.0006321  0.0030989  ... 0.00099422 0.00390812 0.00092706]\n",
    "Laagste MSE op training: 0.00023333266776852734\n",
    "Hoogste MSE op training: 0.26959156306089915\n",
    "threshold_train: 0.0035130688616099625\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.95      0.97    283331\n",
    "           1       0.00      1.00      0.00         0\n",
    "\n",
    "    accuracy                           0.95    283331\n",
    "   macro avg       0.50      0.97      0.49    283331\n",
    "weighted avg       1.00      0.95      0.97    283331\n",
    "\n",
    "confusion matrix\n",
    "[[269164  14167]\n",
    " [     0      0]]\n",
    "Accuracy score: 94.99984117516262\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0035130688616099625\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "```\n",
    "Evaluation TEST set\n",
    "CODE_LAYER neurons: 500\n",
    "62/62 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 17ms/step\n",
    "MSE Test Set: [0.00056565 0.00062129 0.00218412 ... 0.00306568 0.00633676 0.00111103]\n",
    "Laagste MSE op test: 0.00031917546869010533\n",
    "Hoogste MSE op test: 0.0841329429423863\n",
    "classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.96      0.91       984\n",
    "           1       0.95      0.85      0.90       984\n",
    "\n",
    "    accuracy                           0.90      1968\n",
    "   macro avg       0.91      0.90      0.90      1968\n",
    "weighted avg       0.91      0.90      0.90      1968\n",
    "\n",
    "confusion matrix\n",
    "[[943  41]\n",
    " [150 834]]\n",
    "Accuracy score: 90.29471544715447\n",
    "'    p0 p1'\n",
    "'a0: TN FP'\n",
    "'a1: FN TP'\n",
    "MSE Threshold: 0.0035130688616099625\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reconstructie van partially occluded faces\n",
    "\n",
    "Partially occluded faces zijn gezichten die gedeeltelijk bedekt zijn, bijvoorbeeld door een bril, sjaal, hoofddeksel, enzoverder.\n",
    "Via een autoencoder zullen we proberen te achterhalen wat er zich achter die bedekking bevindt en een poging doen het bedekte gedeelte te reconstrueren.\n",
    "Om dit te realiseren moeten we over een trainig set beschikken die bestaat uit zowel bedekte als niet-bedekte afbeeldingen van hetzelfde gezicht.\n",
    "Deze training set gaan we zelf genereren vertrekkende vanaf een bestaande gezichtendataset te vinden in de map 'Faces'. Het bedekken van het gezicht gebeurt door op een willekeurige plaats in de afbeelding een wit vierkant aan te brengen. Een voorbeeld vind je hieronder:\n",
    "\n",
    "![Partially occluded face](./NotebookImages/occlusion_example.png)\n",
    "\n",
    "Zorg er zeker voor dat de trainingset voldoende uitgebreid is. Je kan dezelfde afbeeldingen meerdere malen gebruiken om bedekking op aan te brengen. Zo creÃ«er je een training set die in aantal afbeeldingen een veelvoud is van de originele dataset.\n",
    "\n",
    "- Probeer verschillende types autoencoders uit (convolutional, undercomplete, overcomplete, ...). Varieer tevens het aantal en de grootte van de layers.\n",
    "- De afbeeldingen kunnen best in grootte gereduceerd worden om het berekenbaar te houden.\n",
    "- Probeer verschillende loss functies en optimizers.\n",
    "- Argumenteer en beschrijf telkens de resultaten en bevindingen van een gebruikte autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images inlezen\n",
    "\n",
    "Bij het inlezen van de images wordt direct een aantal bijkomende images aangemaakt:\n",
    "- Een noisy image met randow noise\n",
    "- meerdere uccluded images met random rectangles met een bepaalde maximum-grootte"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "NOISE_LEVEL = 100\n",
    "# OCCLUSION_FACTORS = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "OCCLUSION_FACTORS = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "# Om het geheel op de beschikbare hardware the laten draaien, worden de images gescaled\n",
    "\n",
    "# Een aantal testen uitgevoerd met grotere input\n",
    "WIDTH = 90; HEIGHT = 100\n",
    "\n",
    "# De sizing waarmee ik heb gewerkt om toch iets of wat resultaten te krijgen\n",
    "WIDTH = 60; HEIGHT = 68\n",
    "\n",
    "RESIZE_GRAY = (WIDTH, HEIGHT)\n",
    "RESHAPE_SIZE = (HEIGHT, WIDTH, 1)\n",
    "\n",
    "def add_random_noise(image_np_array):\n",
    "    noise = np.random.randint(-NOISE_LEVEL, NOISE_LEVEL + 1, image_np_array.shape, dtype='int16') \n",
    "    noisy_image_np_array = np.clip(image_np_array + noise, 0, 255).astype('uint8')\n",
    "\n",
    "    return noisy_image_np_array\n",
    "\n",
    "def add_occlusion(incoming_image, occlusion_factor=0.3):\n",
    "\n",
    "    image = incoming_image.copy()\n",
    "    pencil = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    \n",
    "    occlusion_width = random.randint(int(0.5 * width * occlusion_factor), int(width * occlusion_factor))\n",
    "    occlusion_height = random.randint(int(0.5 * height * occlusion_factor), int(height * occlusion_factor))\n",
    "    \n",
    "    left_corner_x = random.randint(0, width - occlusion_width)\n",
    "    left_corner_y = random.randint(0, height - occlusion_height)\n",
    "\n",
    "    pencil.rectangle(\n",
    "        [\n",
    "            left_corner_x, left_corner_y,\n",
    "            left_corner_x + occlusion_width, left_corner_y + occlusion_height\n",
    "        ],\n",
    "        # fill=(255, 255, 255)\n",
    "        fill=(255)\n",
    "    )\n",
    "    return np.array(image)\n",
    "\n",
    "def read_images_from_directory(directory):\n",
    "    # We gaan uit van het originele beeld, dus niet gescaled om de occlusions toe te voegen\n",
    "    image_data = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  # Add other image formats if needed\n",
    "            start_time = time.time()\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            \n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                # print(f\"XXX WIDTH: {width}, HEIGHT: {height}\")  --> De images hebben een size van (180,200)\n",
    "                image_gray_scale = ImageOps.grayscale(img)\n",
    "                image_resized = image_gray_scale.resize(RESIZE_GRAY)\n",
    "\n",
    "                # Read the Image as pixel values\n",
    "                image_pixels = np.array(image_resized)\n",
    "                image_pixels_scaled = image_pixels.astype('float32') / 255.0\n",
    "                image_pixels_scaled = np.reshape(image_pixels_scaled, newshape=RESHAPE_SIZE) \n",
    "  \n",
    "                # Add an image with some random noise too\n",
    "                noisy_image_pixels = add_random_noise(image_pixels)\n",
    "                noisy_image_pixels = noisy_image_pixels.astype('float32') / 255.0\n",
    "                noisy_image_pixels = np.reshape(noisy_image_pixels, newshape=RESHAPE_SIZE)\n",
    "                # display(f\"noisy_image_pixels.shape: {noisy_image_pixels.shape}\")\n",
    "                \n",
    "                # Add occlusions\n",
    "                occlusions = {}\n",
    "                for i, factor in enumerate(OCCLUSION_FACTORS):\n",
    "                    occluded_image_pixels = add_occlusion(image_resized, factor)\n",
    "                    occluded_image_pixels = occluded_image_pixels.astype('float32') / 255.0\n",
    "                    occluded_image_pixels = np.reshape(occluded_image_pixels, newshape=RESHAPE_SIZE)\n",
    "                    # display(f\"occluded_image_pixels.shape: {occluded_image_pixels.shape}\")\n",
    "                    occlusions[f\"v{i}\"] = occluded_image_pixels\n",
    "\n",
    "                end_time = time.time()\n",
    "                base_data = {\n",
    "                    \"filename\": filename,\n",
    "                    \"reading_time\": end_time - start_time,\n",
    "                    \"path\": image_path,\n",
    "                    \"original_width\": width,\n",
    "                    \"original_height\": height,\n",
    "                    \"shape\": image_pixels.shape,\n",
    "                    \"original_image\": image_pixels_scaled,\n",
    "                    \"noisy_image\": noisy_image_pixels,\n",
    "                }\n",
    "                base_data.update(occlusions)\n",
    "                image_data.append(base_data)\n",
    "        else:\n",
    "            display(f\"... Skipping {filename}\")\n",
    "    # Create a DataFrame from the image data\n",
    "    df = pd.DataFrame(image_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = Path(\".\") / \"Faces\"\n",
    "\n",
    "# Read images and create DataFrame\n",
    "image_df = read_images_from_directory(image_directory)\n",
    "\n",
    "# Display the total reading time\n",
    "display_value(\"Inleestijd\", image_df[\"reading_time\"].sum())\n",
    "display_value(\"Gemiddelde inleestijd per image file\", image_df[\"reading_time\"].mean())\n",
    "\n",
    "# Display the DataFrame for visual verification\n",
    "# display(image_df.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display(image_df.iloc[0])\n",
    "display(image_df.iloc[0][\"v0\"].shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display(image_df.iloc[0][\"noisy_image\"].shape)\n",
    "# display(image_df.iloc[0][\"noisy_image\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_images_in_grid(images, columns=5, max_rows=4, names=None):\n",
    "    import math\n",
    "    image_count = len(images)\n",
    "    col = columns\n",
    "    row = min(math.ceil(image_count/columns), max_rows)\n",
    "    plt.style.use(\"grayscale\")\n",
    "    plt.figure(figsize=(col * 1.2,row * 1.2))\n",
    "    for i, image_info in enumerate(images):\n",
    "        if i // col >= row:\n",
    "            break\n",
    "        plt.subplot(row, col, i + 1)\n",
    "        plt.imshow(image_info)\n",
    "        if names is None:\n",
    "            plt.title(i)\n",
    "        else:\n",
    "            plt.xlabel(f\"{i}: {names[i]}-{image_info.shape}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "display_title(\"Images\")\n",
    "display_value(\"image_df.shape\", image_df.shape)\n",
    "display_title(f\"Original resized and scaled\")\n",
    "show_images_in_grid(image_df[\"original_image\"].values, columns=6, max_rows=2, names=image_df[\"filename\"])\n",
    "\n",
    "display_title(\"Noisy scaled\")\n",
    "show_images_in_grid(image_df[\"noisy_image\"].values, columns=6, max_rows=1, names=image_df[\"filename\"])\n",
    "for i in range(0, len(OCCLUSION_FACTORS)):\n",
    "    display_title(f\"Occlusion v{i}({OCCLUSION_FACTORS[i]})\")\n",
    "    show_images_in_grid(image_df[f\"v{i}\"].values, columns=6, max_rows=1, names=image_df[\"filename\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "value_vars = [\"noisy_image\"] + [f\"v{i}\" for i in range(len(OCCLUSION_FACTORS))]\n",
    "display(value_vars)\n",
    "df_input = pd.melt(image_df, id_vars=['original_image', 'filename'], value_vars=value_vars, var_name='occlusion', value_name='input_image')\n",
    "display_value(\"df_input.shape\", df_input.shape)\n",
    "display(df_input.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Shuffle de dataset\n",
    "df_input_shuffled = df_input.sample(frac = 1, replace = False, random_state=101, ignore_index=True)\n",
    "display(df_input_shuffled.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_x_and_y(df, max_rows=4, names=None):\n",
    "    col = 2\n",
    "    plt.figure(figsize=(max_rows, max_rows*2))\n",
    "    plt.style.use(\"grayscale\")\n",
    "    for i, image_record in df.iterrows():\n",
    "        if i >= max_rows:\n",
    "            break\n",
    "        display_value(f\"{i}\", f\"{image_record['filename']}\")\n",
    "\n",
    "        ax1=plt.subplot(max_rows, col, i * 2 + 1)\n",
    "        plt.imshow(image_record[\"original_image\"])\n",
    "        ax1.set_title(f\"Original {image_record['original_image'].shape}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax2=plt.subplot(max_rows, col, i * 2 + 2)\n",
    "        plt.imshow(image_record[\"input_image\"])\n",
    "        ax2.set_title(f\"{image_record['occlusion']}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_title(\"Example images\")\n",
    "display(df_input_shuffled.shape)\n",
    "show_x_and_y(df_input_shuffled, max_rows=10)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Split in train - test - part 1\n",
    "X = np.stack(df_input_shuffled[\"input_image\"])\n",
    "y = np.stack(df_input_shuffled[\"original_image\"])\n",
    "display(X.shape)\n",
    "# display(X[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Split in train - test - part 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# X_train = np.asarray(X_train).reshape((len(X_train), *RESHAPE_SIZE))\n",
    "# y_train = np.asarray(y_train).reshape((len(X_train), *RESHAPE_SIZE))\n",
    "# X_test = np.asarray(X_test).reshape((len(X_train), *RESHAPE_SIZE))\n",
    "# y_test = np.asarray(y_test).reshape((len(X_train), *RESHAPE_SIZE))\n",
    "display_value(\"type(X_train)\", type(X_train))\n",
    "display_value(\"X_train.shape\", X_train.shape)\n",
    "# display_value(\"X_train[0]\", X_train[0])\n",
    "display_value(\"type(X_test)\", type(X_test))\n",
    "display_value(\"X_test.shape\", X_test.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional function(s)\n",
    "\n",
    "### Image display"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_images(max_rows=5, **image_arrays):\n",
    "    # Create a figure to display the images\n",
    "    plt.figure(figsize=(max_rows, max_rows*4))\n",
    "    # plt.figure(figsize=(15, 10))\n",
    "    plt.style.use(\"ggplot\")\n",
    "\n",
    "    columns = len(image_arrays)  # Nbr of columns equals number of names arrays passed\n",
    "    for i in range(max_rows):\n",
    "        col = 1\n",
    "        for k,v in image_arrays.items():\n",
    "            # Display the first image\n",
    "            ax_c = plt.subplot(max_rows, columns, i * columns + col)\n",
    "            plt.imshow(v[i])\n",
    "            # plt.gray()\n",
    "            plt.axis(\"off\")\n",
    "            ax_c.set_title(f\"{i}:{k}\")\n",
    "            col = col+1\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Additional functions\n",
    "\n",
    "# Additional loss function based on Structural Simularity index\n",
    "# SSIM is [-1, 1] where 1 is perfect match\n",
    "def ssim_mean_value(y_true, y_pred):\n",
    "  return tf.reduce_mean(tf.image.ssim(img1=y_true, img2=y_pred, max_val=1.0))\n",
    "\n",
    "# Using the function as a loss function\n",
    "def ssim_loss(y_true, y_pred):\n",
    "  return -1 * ssim_mean_value(y_true, y_pred)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display History for a trained encoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "def display_history(history, title=\"XXXXXXXXXXX\"): \n",
    "    \n",
    "    # history_df = pd.DataFrame(history.history)[[\"loss\", \"val_loss\"]]\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_df.plot(\n",
    "        kind=\"line\",\n",
    "        figsize=(10, 5),\n",
    "        xlim=[0, len(history.epoch)+2], grid=True,\n",
    "        xlabel=\"Epoch\",\n",
    "        # style=[\"r--\", \"g--\", \"b--\", \"y--\"])\n",
    "        style={\n",
    "            \"MSE\": \"r-\", \"val_MSE\": \"r--\",\n",
    "            \"loss\": \"b-\", \"val_loss\": \"b--\",\n",
    "            \"Binary_Crossentropy\": \"y-\", \"val_Binary_Crossentropy\": \"y--\",\n",
    "            \"ssim_mean_value\": \"g-\", \"val_ssim_mean_value\": \"g--\",\n",
    "            \"accuracy\": \"c-\", \"accuracy\": \"c--\",\n",
    "        }\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to calculate base metrics and give a visual\n",
    "def reconstruction_error_display(image_true, image_input, image_predicted, title=\"Metrics\"):\n",
    "\n",
    "    def _show_row(index):\n",
    "        plt.figure(figsize=(4, 16))\n",
    "        plt.style.use(\"ggplot\")\n",
    "\n",
    "        r = 4\n",
    "        c = 3\n",
    "        ax_mse_min = plt.subplot(4, 3, 1)\n",
    "        plt.imshow(image_true[index])\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Correct\", fontsize=MEDIUM)\n",
    "    \n",
    "        ax_mse_min = plt.subplot(4, 3, 2)\n",
    "        plt.imshow(image_input[index])\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Input\", fontsize=MEDIUM)\n",
    "    \n",
    "        ax_mse_min = plt.subplot(4, 3, 3)\n",
    "        plt.imshow(image_predicted[index])\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Reconstruction\", fontsize=MEDIUM)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    display_title(title)\n",
    "\n",
    "    # Bereken de reconstruction error voor elke predictie\n",
    "\n",
    "    # MSE\n",
    "    reconstruction_error_mse = np.mean(np.power(image_true - image_predicted, 2), axis=(1,2))\n",
    "    display(reconstruction_error_mse.shape)\n",
    "    min_reconstruction_error_mse_index = np.argmin(reconstruction_error_mse)\n",
    "    max_reconstruction_error_mse_index = np.argmax(reconstruction_error_mse)\n",
    "    display_value(f\"Laagste MSE: Index[{min_reconstruction_error_mse_index}]\", reconstruction_error_mse[min_reconstruction_error_mse_index])\n",
    "    display_value(f\"Laagste MSE: Index[{max_reconstruction_error_mse_index}]\", reconstruction_error_mse[max_reconstruction_error_mse_index])\n",
    "\n",
    "    # SSIM\n",
    "    display_value(\"Gemiddelde Structural Simularity index\", ssim_mean_value(image_true, image_predicted))\n",
    "\n",
    "    #\n",
    "    structural_similarity_index = tf.image.ssim(img1=image_true, img2=image_predicted, max_val=1.0)\n",
    "    display(structural_similarity_index.shape)\n",
    "    # xx_numpy = structural_similarity_index.numpy()\n",
    "    # display(xx_numpy.shape)\n",
    "    min_structural_similarity_index_index = np.argmin(structural_similarity_index)\n",
    "    max_structural_similarity_index_index = np.argmax(structural_similarity_index)\n",
    "\n",
    "    display_value(f\"Laagste SSI: Index[{min_structural_similarity_index_index}]\", structural_similarity_index[min_structural_similarity_index_index])\n",
    "    display_value(f\"Hoogste SSI: Index[{max_structural_similarity_index_index}]\", structural_similarity_index[max_structural_similarity_index_index])\n",
    "\n",
    "    # Create a figure to display the images\n",
    "    # Adjust layout\n",
    "    # plt.close()\n",
    "\n",
    "    display_title(f\"{title}: Minimum MSE\")\n",
    "    _show_row(min_reconstruction_error_mse_index)\n",
    "    display_title(f\"{title}: Maximum MSE\")\n",
    "    _show_row(max_reconstruction_error_mse_index)\n",
    "\n",
    "    display_title(f\"{title}: Minimum SSI\")\n",
    "    _show_row(min_structural_similarity_index_index)\n",
    "    display_title(f\"{title}: Maximum SSI\")\n",
    "    _show_row(max_structural_similarity_index_index)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Show some input (X_train) and expected (y_train)\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Definitions\n",
    "\n",
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"loss\",           # metric to monitor\n",
    "    patience=3,               # stop when no improvement after 10 consecutive epochs\n",
    "    mode=\"min\",               # stop when metric stops decreasing\n",
    "    restore_best_weights=True,\n",
    "    verbose=True,             # display the actions taken\n",
    ")\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    # min_delta=0.0001,\n",
    "    # cooldown=0,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,             # display the actions taken\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcomplete AutoEncoder (MSE)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een eenvoudige overcomplete met slechts 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = WIDTH * HEIGHT * 3\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_1 = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_1.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_1.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Overcomplete, code layer[{ENCODING_DIM}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Predict the images from the Training set\n",
    "predicted_train = autoencoder_1.predict(X_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display_title(\"Metrics\")\n",
    "\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 1: TRAINING SET\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Show examples for training set predictions\n",
    "display_title(\"Autoencoder 1: Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Predict the iamges from the test set\n",
    "predicted_test = autoencoder_1.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 1: TEST SET\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Show examples for testing set predictions\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcomplete AutoEncoder (Structural Similarity Index)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een eenvoudige overcomplete met slechts 1 layer, dezelde structuur als 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = WIDTH * HEIGHT * 3\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_2 = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_2.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_2.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Overcomplete, code layer[{ENCODING_DIM}]\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder 2: Predict the images for the training set\n",
    "predicted_train = autoencoder_2.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 2: TRAINING SET\")\n",
    "display_title(\"Autoencoder 2: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder 2: Predict the images for the test set\n",
    "predicted_test = autoencoder_2.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 2: TEST SET\")\n",
    "display_title(\"Autoencoder 2: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> Overcomplete Autoencoder Conclusions\n",
    "\n",
    "##### Preprocessing\n",
    "- het verwerken van image data vraagt serieus wat rekenkracht. Er is gekozen om de originele images te resizen naar iets dat meer bruikbaar is op de voor handen zijnde infrastructuur.\n",
    "  Dit heeft volgens mij een streke invloed of de accuraatheid van het model in de zin dat er een reele kans bestaat op overfitting.\n",
    "\n",
    "- Het is spijtig dat de verschillende libraries die toch deel uitmaken van het eco-systeem apis hebben die zo verschillend zijn.\n",
    "\n",
    "- Ik vermoed dat het toevoegen van een gewone \"noisy image\" aan de testset een positieve invloed heeft op het reconstructief vermogen van het decoder gedeelte.\n",
    "  Dit blijkt ook uit de similariry index die oploopt to dicht tegen 1.\n",
    "\n",
    "##### Train\n",
    "- Als lossfunctie is the MeanSquaredError en de Simularity Index gebruikt met vergelijkbare resultaten. Inspectie van de grafiek geeft een lichte stijging van de loss-functie voor de validation set, wat eventueel kan wijzen op een overfitting.\n",
    "- Het trainen van het net vraagt nogal veel resources. Bij een image met shape 90*100 moest ik de GPU kernel telken opnieuw initialiseren (Windes + WSL2). Een adequate hardwareomgeving is zeer belangrijk om onderzoek te kunnen doen naar variaties van models.\n",
    "\n",
    "- De meeste trials die ik heb geprobeerd is op een image size van (60, 67), dit is original.size/3.\n",
    "  Bepaalde testen zijn uitgevoerd met (90/100). Het is duidelijk dat dit een beter resultaat geeft, maar verandert niets aan de spirit van de resultaten verkregen met een lagere resolutie.\n",
    " \n",
    "##### Test\n",
    "- Deze sample is uit de training set gehaald en worden niet gebruikt tijdens training\n",
    "- De grootte van de testset wordt bepaald door 1 of meerdere keren de frauduleuze transacties te gebruiken (de training set wordt hierdood kleiner)\n",
    "\n",
    "- Om de classificatie uit te voeren wordt terug gekeken naar de MSE\n",
    "\n",
    "##### Evaluatie\n",
    "- Gewoon visueel kunnen we stellen dat de reconstructie vrij gehoorlijk werkt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete AutoEncoder (MSE-1)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een undercomplete met sterk gereduceerde code layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = int((WIDTH * HEIGHT) / 4)\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_3a = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_3a.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_3a.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_3a.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Undercomplete, code layer[{ENCODING_DIM}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_3a.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 3a: TRAINING SET\")\n",
    "display_title(\"Autoencoder 3a: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder 3: Predict the images for the test set\n",
    "predicted_test = autoencoder_3a.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 3a: TEST SET\")\n",
    "display_title(\"Autoencoder 3a: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete AutoEncoder (MSE-2)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een undercomplete met sterk gereduceerde code layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = int((WIDTH * HEIGHT) / 8)\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_3b = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_3b.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_3b.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_3b.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Undercomplete, code layer[{ENCODING_DIM}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_3b.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 3b: TRAINING SET\")\n",
    "display_title(\"Autoencoder 3b: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n",
    "\n",
    "# Autoencoder 3: Predict the images for the test set\n",
    "predicted_test = autoencoder_3b.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 3b: TEST SET\")\n",
    "display_title(\"Autoencoder 3b: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete AutoEncoder (MSE-3)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een undercomplete met sterk gereduceerde code layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = int((WIDTH * HEIGHT) / 16)\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_3c = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_3c.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_3c.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_3c.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Undercomplete, code layer[{ENCODING_DIM}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_3c.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 3c: TRAINING SET\")\n",
    "display_title(\"Autoencoder 3c: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n",
    "\n",
    "# Autoencoder 3: Predict the images for the test set\n",
    "predicted_test = autoencoder_3c.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 3c: TEST SET\")\n",
    "display_title(\"Autoencoder 3c: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete AutoEncoder (MSE-4)\n",
    "\n",
    "#### Construction\n",
    "\n",
    "Een undercomplete met sterk gereduceerde code layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ENCODING_DIM = int((WIDTH * HEIGHT) / 32)\n",
    "\n",
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "# Flatten the input\n",
    "encoded = Flatten()(input_data)\n",
    "# Encoder layer with L1 regularization\n",
    "encoded = Dense(ENCODING_DIM, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-7))(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(WIDTH * HEIGHT, activation='sigmoid')(encoded)\n",
    "decoded = Reshape(target_shape=(HEIGHT, WIDTH, 1))(decoded)\n",
    "\n",
    "# AE\n",
    "autoencoder_3d = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_3d.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "display_value(\"Code layer size\", ENCODING_DIM)\n",
    "autoencoder_3d.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and training monitoring\n",
    "history = autoencoder_3d.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Undercomplete, code layer[{ENCODING_DIM}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_3d.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 3d: TRAINING SET\")\n",
    "display_title(\"Autoencoder 3d: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n",
    "\n",
    "# Autoencoder 3: Predict the images for the test set\n",
    "predicted_test = autoencoder_3d.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 3c: TEST SET\")\n",
    "display_title(\"Autoencoder 3d: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> Undercomplete Autoencoder Conclusions\n",
    "\n",
    "##### Train\n",
    "- Het training gaat veel sneller dan bij overcomplete.\n",
    "- Het aantal epochs nodig is hoger dan bij overcomplete.\n",
    " \n",
    "##### Evaluatie\n",
    "- Ook hier werkt de reconstructie vrij behoorlijk, zij het dat de resultaten visueel slechter zijn.\n",
    "- Voor bepaalde use-cases, waar snelheid belangrijker is dan accuraatheid ven de gereconstrueerde beelden, zijn undercomplete AEs duidelijk een optie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution AE (Small)\n",
    "\n",
    "#### Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "\n",
    "# Define the encoder\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_data)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name=\"out\")(x)\n",
    "\n",
    "# Define the decoder\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# AE 1\n",
    "autoencoder_4a = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_4a.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        # keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "autoencoder_4a.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train\n",
    "history = autoencoder_4a.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Convolutional\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_4a.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 4a: TRAINING SET\")\n",
    "display_title(\"Autoencoder 4a: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n",
    "\n",
    "# Autoencoder: Predict the images for the test set\n",
    "predicted_test = autoencoder_4a.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 3c: TEST SET\")\n",
    "display_title(\"Autoencoder 4a: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution AE (Bigger)\n",
    "\n",
    "#### Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_data = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "\n",
    "# Define the encoder\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(input_data)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name=\"out\")(x)\n",
    "\n",
    "# Define the decoder\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# AE\n",
    "autoencoder_4b = Model(input_data, decoded)\n",
    "\n",
    "# Compile\n",
    "autoencoder_4b.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    # loss=ssim_loss,\n",
    "    metrics=[\n",
    "        ssim_mean_value,\n",
    "        # keras.metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        keras.metrics.BinaryCrossentropy(name=\"Binary_Crossentropy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "autoencoder_4b.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train\n",
    "history = autoencoder_4b.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    shuffle=True,\n",
    "    validation_split=0.3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "display_history(history, title=f\"Convolutional\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Autoencoder: Predict the images for the training set\n",
    "predicted_train = autoencoder_4b.predict(X_train)\n",
    "reconstruction_error_display(y_train, X_train, predicted_train, \"Autoencoder 4b: TRAINING SET\")\n",
    "display_title(\"Autoencoder 4b: : TRAIN Visual inspection\")\n",
    "show_images(max_rows=10, X_train=X_train, y_train=y_train, predicted_train=predicted_train)\n",
    "\n",
    "# Autoencoder: Predict the images for the test set\n",
    "predicted_test = autoencoder_4b.predict(X_test)\n",
    "reconstruction_error_display(y_test, X_test, predicted_test, \"Autoencoder 4b: TEST SET\")\n",
    "display_title(\"Autoencoder 4b: : TEST Visual inspection\")\n",
    "show_images(max_rows=10, X_test=X_test, y_test=y_test, predicted_test=predicted_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Image segmentation\n",
    "\n",
    "Autoencoders kunnen ook getraind worden om image segmentation uit te voeren. Segmentatie betekent dat je specifieke objecten in de afbeelding gaat afzonderen van de rest van de afbeelding. In de praktijk komt dit meestal neer op het inkleuren het desbetreffende object in de afbeelding. Image segmentation vindt onderandere zijn toepassing bij self-driving cars, video surveillance en medical imaging. Bij deze opdracht is het de bedoeling om longen te segmenteren uit X-ray afbeeldingen.\n",
    "\n",
    "Foto's van de longen zijn te vinden in de map Lung_images. \n",
    "\n",
    "De labels zijn in dit geval mask afbeeldingen die de exacte locatie van de longen aanduiden. Deze masks bevinden zich in de map Lung_masks.\n",
    "\n",
    "Ga bij deze opdracht als volgt te werk:\n",
    "\n",
    "- Lees de afbeeldingen in en schaal deze allemaal naar dezelfde grootte. Bijvoorbeeld naar 400x400 pixels. Lagere resolutie mag ook als je merkt dat de systeemvereisten niet volstaan. Voor deze toepassing mag alles naar grijswaarden worden omgezet.\n",
    "\n",
    "- Maak een training set en test set aan. Stop een 20-tal afbeeldingen in de test set.\n",
    "\n",
    "- Train een convolutional autoencoder op de training set. De output layer moet dezelfde dimensie hebben als de mask images. De autoencoder wordt namelijk getraind om op basis van een long-scan een mask te genereren die zo goed mogelijk de ground truth mask benadert. Dit vereist echter een aangepaste loss functie om de autoencoder mee te trainen. Cross-entropy gebaseerde loss functies zijn hiervoor niet altijd geschikt. In de praktijk wordt dikwijls de dice coefficient loss gebruikt. Deze kijkt naar de overlap tussen twee data samples. In dit geval hoeveel de door de autoencoder gegeneerde mask overlapt met de ground truth mask. Deze dice loss moet je zelf als custom loss meegeven met het neuraal netwerk.\n",
    "\n",
    "```Python\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2.*intersection + smooth)/(K.sum(K.square(y_true),-1)+ K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "```   \n",
    "\n",
    "- Test de autoencoder op de afbeeldingen uit de test set. Visualiseer de gegeneerde mask en vergelijk met de werkelijke mask. Probeer de segmentatie te verbeteren via hyperparameter tuning. Gebruik hiervoor naast visuele inspectie ook de dice coefficient als metric.\n",
    "\n",
    "- U-net is een veelgebruikt neuraal netwerk voor medical image segmentation. Een voorbeeld hiervan kan je vinden op https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277. Implementeer, train en test dit netwerk. Gebruik ook eens de dice coefficient loss als custom loss functie. Bespreek de resultaten.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dice coefficient loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Uitwerking image segmentation\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
