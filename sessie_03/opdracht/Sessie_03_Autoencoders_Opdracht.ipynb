{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht Autoencoders\n",
    "\n",
    "\n",
    "Autoencoders zijn neurale netwerken die getraind worden om hun eigen input te reconstrueren. De toepassingen die mogelijk gemaakt worden door autoencoders vari√´ren van compressie, denoising, reconstructie van afbeeldingen, unsupervised pre-training tot en met one-class classificatie, resolution upscaling, recommendation systems, anomaly detection en image segmentation.\n",
    "\n",
    "Deze opdracht bestaat uit 3 deelopdrachten:\n",
    "1. Anomaly detection\n",
    "2. Denoising \n",
    "3. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fraude detectie\n",
    "\n",
    "Een anomalie is een datapunt dat qua statistische eigenschappen sterk afwijkt van de meerderheid van de datapunten. Zo kunnen ook frauduleuze banktransacties aanzien worden als anomalie√´n.\n",
    "Een van de grootste uitdagingen bij het detecteren van anomali√´n is de ongebalanceerdheid van de data. Deze anomalie√´n komen per definitie vrij uitzonderlijk voor. \n",
    "\n",
    "Een mogelijke benadering voor het detecteren van anomalie√´n is leren van de distributie van normale datapunten, in dit geval normale banktransacties. Vervolgens kan je nieuwe datapunten classificeren als anomalie√´n wanneer ze volgens de geleerde distributie heel onwaarschijnlijk zijn.\n",
    "\n",
    "Autoencoders kunnen de distributie van de normale datapunten leren door deze normale datapunten te leren reconstrueren. De getrainde autoencoder zal vervolgens moeite hebben om anamalie√´n te reconstrueren met als resultaat een hoge reconstructie-error, bijvoorbeeld de MSE = Mean Squared Error. https://keras.io/losses/\n",
    "\n",
    "ùëÄùëÜùê∏=ùëñùëõ‚àëùëõùëñ=1(ùëå‚àíùëåÃÇ )2\n",
    "\n",
    "Een transactie kan dus als frauduleus verondersteld worden wanneer de reconstructie-error boven een zekere threshold uitsteekt. \n",
    "Men spreekt van een one-class classifier.\n",
    "\n",
    "\n",
    "Gegeven is een dataset met banktransacties. Bepaalde features zijn geanonimiseerd (aangeduid met V). Andere features duiden het bedrag en het tijdstip aan. Alle transacties kregen het label 1 (frauduleus) of 0 (normale transactie).\n",
    "\n",
    "\n",
    "\n",
    "Doorloop de volgende stappen:\n",
    "\n",
    "- Controleer in welke mate de dataset gebalanceerd is.\n",
    "\n",
    "- Preprocessing.\n",
    "\n",
    "- Opbouwen van een training set en test set.\n",
    "\n",
    "- Train de autoencoder.\n",
    "\n",
    "- Gebruik de classificatie-error om een transactie te classificeren als normaal of frauduleus.\n",
    "\n",
    "- Test de autoencoder op de test set.\n",
    "\n",
    "- Voer hyperparameter tuning uit op het neuraal netwerk, maar zoek ook een gepaste waarde voor de threshold op de reconstructie error. \n",
    "\n",
    "- Beantwoord de vragen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization,concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "# Voor GPU support\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('creditcard.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse van de dataset\n",
    "\n",
    "- Controleer in welke mate de dataset ongebalanceerd is. Maak daarvoor een histogram van de klasselabels. Een geschikte plot is de seaborn countplot (https://seaborn.pydata.org/generated/seaborn.countplot.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van de dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Kuis de dataset op. Verwijder de irrelevante features.\n",
    "- Splits op in een trainig set en test set. Zorg ervoor dat je een gebalanceerde test set bekomt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontwerpen, trainen en hyperparameter tuning v.d. autoencoder\n",
    "\n",
    "- Ontwerp en train een autoencoder. Gebruik de MSE (Mean Squared Error) loss function. Kies zelf de grootte van het neurale netwerk. Deze kan je later bij de hyperparametertuning nog aanpassen.\n",
    "- Kies een threshold voor de MSE waarmee je beslist of een transactie al dan niet frauduleus is.\n",
    "- Gebruik de test set om de autoencoder te evalueren. Gebruik hiervoor de accuraatheid, confusion matrix, recall, precision, f1-score en de ROC.\n",
    "- Voer hyperparameter tuning uit om de performantie te verhogen. Zoek de optimale MSE threshold. Visualeer welke punten boven de threshold liggen en welke eronder. Gebruik kleur om de verschillende klasses aan te duiden.\n",
    "- Stel dat de bank zoveel mogelijk false-negatives (frauduleuze transacties die als normaal werden geclassificeerd) wil vermijden. Welke aanpassingen zou je daarvoor kunnen doen? Test deze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontwerp en training van de autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testen van de autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning. Zoek naar de optimale waarde voor de MSE-threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vermijden van false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beantwoord de onderstaande vragen\n",
    "\n",
    "-  Welk type autoencoder is het meest geschikt (undercomplete, overcomplete, convolutional, ...)? Waarom?\n",
    "\n",
    "- Zou het zinvol zijn om de categorical cross-entropy te gebruiken als loss functie?\n",
    "\n",
    "- Plot een histogram van de MSE waarden op de training set. Hoe zijn deze verdeeld? Kan je hieruit een schatting maken van waar de threshold zal komen te liggen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANTWOORDEN:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reconstructie van partially occluded faces\n",
    "\n",
    "Partially occluded faces zijn gezichten die gedeeltelijk bedekt zijn, bijvoorbeeld door een bril, sjaal, hoofddeksel, enzoverder.\n",
    "Via een autoencoder zullen we proberen te achterhalen wat er zich achter die bedekking bevindt en een poging doen het bedekte gedeelte te reconstrueren.\n",
    "Om dit te realiseren moeten we over een trainig set beschikken die bestaat uit zowel bedekte als niet-bedekte afbeeldingen van hetzelfde gezicht.\n",
    "Deze training set gaan we zelf genereren vertrekkende vanaf een bestaande gezichtendataset te vinden in de map 'Faces'. Het bedekken van het gezicht gebeurt door op een willekeurige plaats in de afbeelding een wit vierkant aan te brengen. Een voorbeeld vind je hieronder:\n",
    "\n",
    "![Partially occluded face](./NotebookImages/occlusion_example.png)\n",
    "\n",
    "Zorg er zeker voor dat de trainingset voldoende uitgebreid is. Je kan dezelfde afbeeldingen meerdere malen gebruiken om bedekking op aan te brengen. Zo cre√´er je een training set die in aantal afbeeldingen een veelvoud is van de originele dataset.\n",
    "\n",
    "- Probeer verschillende types autoencoders uit (convolutional, undercomplete, overcomplete, ...). Varieer tevens het aantal en de grootte van de layers.\n",
    "- De afbeeldingen kunnen best in grootte gereduceerd worden om het berekenbaar te houden.\n",
    "- Probeer verschillende loss functies en optimizers.\n",
    "- Argumenteer en beschrijf telkens de resultaten en bevindingen van een gebruikte autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image segmentation\n",
    "\n",
    "Autoencoders kunnen ook getraind worden om image segmentation uit te voeren. Segmentatie betekent dat je specifieke objecten in de afbeelding gaat afzonderen van de rest van de afbeelding. In de praktijk komt dit meestal neer op het inkleuren het desbetreffende object in de afbeelding. Image segmentation vindt onderandere zijn toepassing bij self-driving cars, video surveillance en medical imaging. Bij deze opdracht is het de bedoeling om longen te segmenteren uit X-ray afbeeldingen.\n",
    "\n",
    "Foto's van de longen zijn te vinden in de map Lung_images. \n",
    "\n",
    "De labels zijn in dit geval mask afbeeldingen die de exacte locatie van de longen aanduiden. Deze masks bevinden zich in de map Lung_masks.\n",
    "\n",
    "Ga bij deze opdracht als volgt te werk:\n",
    "\n",
    "- Lees de afbeeldingen in en schaal deze allemaal naar dezelfde grootte. Bijvoorbeeld naar 400x400 pixels. Lagere resolutie mag ook als je merkt dat de systeemvereisten niet volstaan. Voor deze toepassing mag alles naar grijswaarden worden omgezet.\n",
    "\n",
    "- Maak een training set en test set aan. Stop een 20-tal afbeeldingen in de test set.\n",
    "\n",
    "- Train een convolutional autoencoder op de training set. De output layer moet dezelfde dimensie hebben als de mask images. De autoencoder wordt namelijk getraind om op basis van een long-scan een mask te genereren die zo goed mogelijk de ground truth mask benadert. Dit vereist echter een aangepaste loss functie om de autoencoder mee te trainen. Cross-entropy gebaseerde loss functies zijn hiervoor niet altijd geschikt. In de praktijk wordt dikwijls de dice coefficient loss gebruikt. Deze kijkt naar de overlap tussen twee data samples. In dit geval hoeveel de door de autoencoder gegeneerde mask overlapt met de ground truth mask. Deze dice loss moet je zelf als custom loss meegeven met het neuraal netwerk.\n",
    "\n",
    "```Python\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2.*intersection + smooth)/(K.sum(K.square(y_true),-1)+ K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "```   \n",
    "\n",
    "- Test de autoencoder op de afbeeldingen uit de test set. Visualiseer de gegeneerde mask en vergelijk met de werkelijke mask. Probeer de segmentatie te verbeteren via hyperparameter tuning. Gebruik hiervoor naast visuele inspectie ook de dice coefficient als metric.\n",
    "\n",
    "- U-net is een veelgebruikt neuraal netwerk voor medical image segmentation. Een voorbeeld hiervan kan je vinden op https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277. Implementeer, train en test dit netwerk. Gebruik ook eens de dice coefficient loss als custom loss functie. Bespreek de resultaten.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice coefficient loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking image segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
