{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Bayessearch cv uit Scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Import Keras libraries\n",
    "\n",
    "# Import Tensorflow libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv('cancer.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "dataset.drop('id',axis=1, inplace=True)\n",
    "\n",
    "# Remove right column (unnamed)\n",
    "dataset.drop(dataset.columns[31],axis=1,inplace=True)\n",
    "\n",
    "# diagnosis labels M -> 1 and B -> 0\n",
    "dataset.diagnosis.replace(['M', 'B'], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset up in features and targets\n",
    "y = dataset.diagnosis\n",
    "X = dataset.drop('diagnosis',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state =0)\n",
    "\n",
    "# feature normalization\n",
    "# via robustscaler: This Scaler removes the median and scales the data according to the quantile range \n",
    "\n",
    "Rscaler = RobustScaler()\n",
    "Rscaler.fit(X_train)\n",
    "\n",
    "X_train = Rscaler.transform(X_train)\n",
    "X_test = Rscaler. transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 22 candidates, totalling 88 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9859154929577465\n",
      "Best parameters : {'C': 1.0, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        90\n",
      "           1       0.93      0.96      0.94        53\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       143\n",
      "   macro avg       0.95      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "[[86  4]\n",
      " [ 2 51]]\n",
      "95.8041958041958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 out of  88 | elapsed:    2.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  88 out of  88 | elapsed:    2.4s finished\n",
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM (grid search)\n",
    "\n",
    "model = SVC()\n",
    "parameters = [ \n",
    "        {'kernel': ['linear'], 'C': np.linspace(1,20,10)},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]},\n",
    "        {'kernel': ['poly'], 'C':[1, 10]} ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 4,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 3)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9835680751173709\n",
      "Best parameters : {'C': 1.7566526744992272, 'gamma': 0.4914672460054458, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        90\n",
      "           1       0.96      0.94      0.95        53\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "96.5034965034965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM (random search)\n",
    "\n",
    "model = SVC()\n",
    "parameters = {'kernel': ['linear','rbf','poly'],\n",
    "              'C': uniform(0.01, 100), \n",
    "              'gamma': uniform(0.001, 2)}\n",
    "\n",
    "\n",
    "n_iter_search = 40\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=4,n_iter=n_iter_search)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "/home/wouter/tensorflow/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "/home/wouter/tensorflow/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9835680751173709\n",
      "Best parameters : {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        90\n",
      "           1       0.98      0.96      0.97        53\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "[[89  1]\n",
      " [ 2 51]]\n",
      "97.9020979020979\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM (Bayes optimization )\n",
    "\n",
    "model = SVC()\n",
    "parameters = {'kernel': ['linear','rbf','poly'],\n",
    "              'C': (0.01, 100,'uniform'), # \n",
    "              'gamma': (0.001, 2,'uniform')}\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "Bayes_search = BayesSearchCV(model,parameters,n_iter=n_iter_search,cv=4,verbose=1)\n",
    "\n",
    "\n",
    "Bayes_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = Bayes_search.best_score_ \n",
    "best_parameters = Bayes_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', Bayes_search.best_score_)\n",
    "print('Best parameters :',Bayes_search.best_params_  )\n",
    "\n",
    "y_pred = Bayes_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv('cancer.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "dataset.drop('id',axis=1, inplace=True)\n",
    "\n",
    "# Remove right column (unnamed)\n",
    "dataset.drop(dataset.columns[31],axis=1,inplace=True)\n",
    "\n",
    "# diagnosis labels M -> 1 and B -> 0\n",
    "dataset.diagnosis.replace(['M', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "\n",
    "# Split dataset up in features and targets\n",
    "y = dataset.diagnosis\n",
    "X = dataset.drop('diagnosis',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state =0)\n",
    "\n",
    "# Convert to numpy array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# One-hot encoding of the targets\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# Feature normalization\n",
    "# via robustscaler: This Scaler removes the median and scales the data according to the quantile range \n",
    "\n",
    "Rscaler = RobustScaler()\n",
    "Rscaler.fit(X_train)\n",
    "\n",
    "X_train = Rscaler.transform(X_train)\n",
    "X_test = Rscaler. transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam',activation = 'relu',dropout_rate = 0.0, kernel_initializer='uniform',neurons = 10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=kernel_initializer,activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(neurons, kernel_initializer=kernel_initializer,activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(neurons, kernel_initializer=kernel_initializer,activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer,metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] activation=relu, batch_size=8, dropout_rate=0.0, epochs=50, optimizer=SGD \n",
      "Epoch 1/50\n",
      "284/284 [==============================] - 9s 31ms/step - loss: 0.3610 - acc: 0.8732\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2943 - acc: 0.9014\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.2869 - acc: 0.9085\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1638 - acc: 0.9648\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 0s 981us/step - loss: 0.2582 - acc: 0.9049\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 0s 507us/step - loss: 0.1438 - acc: 0.9577\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2081 - acc: 0.9401\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.2058 - acc: 0.9331\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1837 - acc: 0.9507\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1533 - acc: 0.9613\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1905 - acc: 0.9472\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1554 - acc: 0.9613\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1717 - acc: 0.9437\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 0s 908us/step - loss: 0.1905 - acc: 0.9472\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 0s 580us/step - loss: 0.1308 - acc: 0.9683\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 0s 782us/step - loss: 0.1310 - acc: 0.9648\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1154 - acc: 0.9683\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9824\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1441 - acc: 0.9507\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 0s 590us/step - loss: 0.1510 - acc: 0.9577\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1440 - acc: 0.9613\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 0s 909us/step - loss: 0.1333 - acc: 0.9718\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 0s 738us/step - loss: 0.1247 - acc: 0.9754\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1284 - acc: 0.9613\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1336 - acc: 0.9577\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 0s 996us/step - loss: 0.1016 - acc: 0.9683\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 0s 932us/step - loss: 0.1871 - acc: 0.9577\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1124 - acc: 0.9613\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 0s 611us/step - loss: 0.1479 - acc: 0.9648\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1570 - acc: 0.9507\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 0s 966us/step - loss: 0.1310 - acc: 0.9542\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1657 - acc: 0.9507\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 0s 931us/step - loss: 0.2103 - acc: 0.9472\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1291 - acc: 0.9613\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 0s 981us/step - loss: 0.1000 - acc: 0.9718\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 0s 851us/step - loss: 0.1785 - acc: 0.9472\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 0s 974us/step - loss: 0.1754 - acc: 0.9542\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1061 - acc: 0.9718\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0747 - acc: 0.9754\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 0s 838us/step - loss: 0.1177 - acc: 0.9613\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 0s 856us/step - loss: 0.1347 - acc: 0.9683\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 0s 934us/step - loss: 0.1482 - acc: 0.9613\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1050 - acc: 0.9577\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 0s 980us/step - loss: 0.0998 - acc: 0.9648\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 0s 900us/step - loss: 0.1330 - acc: 0.9577\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 0s 838us/step - loss: 0.1148 - acc: 0.9754\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 0s 745us/step - loss: 0.1402 - acc: 0.9613\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 0s 952us/step - loss: 0.1270 - acc: 0.9648\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 0s 941us/step - loss: 0.1069 - acc: 0.9789\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0938 - acc: 0.9683\n",
      "142/142 [==============================] - 4s 26ms/step\n",
      "284/284 [==============================] - 0s 364us/step\n",
      "[CV]  activation=relu, batch_size=8, dropout_rate=0.0, epochs=50, optimizer=SGD, score=0.9647887323943662, total=  28.3s\n",
      "[CV] activation=relu, batch_size=8, dropout_rate=0.0, epochs=50, optimizer=SGD \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "284/284 [==============================] - 9s 32ms/step - loss: 0.3736 - acc: 0.8169\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.3552 - acc: 0.8697\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.9190\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2103 - acc: 0.9261\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1531 - acc: 0.9437\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1502 - acc: 0.9437\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0982 - acc: 0.9789\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2349 - acc: 0.9120\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1601 - acc: 0.9613\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1178 - acc: 0.9577\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1751 - acc: 0.9472\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 0s 821us/step - loss: 0.1411 - acc: 0.9648\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 0s 497us/step - loss: 0.1180 - acc: 0.9648\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 0s 555us/step - loss: 0.1168 - acc: 0.9754\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1687 - acc: 0.9437\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1675 - acc: 0.9437\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1777 - acc: 0.9437\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.9683\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1084 - acc: 0.9613\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1726 - acc: 0.9542\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1254 - acc: 0.9754\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1678 - acc: 0.9401\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1108 - acc: 0.9613\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0885 - acc: 0.9718\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1264 - acc: 0.9542\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0750 - acc: 0.9789\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0859 - acc: 0.9648\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1233 - acc: 0.9648\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1188 - acc: 0.9613\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.9754\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0875 - acc: 0.9789\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1049 - acc: 0.9683\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 0s 908us/step - loss: 0.1060 - acc: 0.9577\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 0s 731us/step - loss: 0.0480 - acc: 0.9965\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 0s 586us/step - loss: 0.0977 - acc: 0.9754\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0455 - acc: 0.9965\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 0s 543us/step - loss: 0.0740 - acc: 0.9894\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0604 - acc: 0.9824\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9894\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.0575 - acc: 0.9894\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 0s 730us/step - loss: 0.1301 - acc: 0.9648\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 0s 615us/step - loss: 0.0587 - acc: 0.9894\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.0471 - acc: 0.9894\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 0s 659us/step - loss: 0.0639 - acc: 0.9930\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 0s 594us/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 0s 654us/step - loss: 0.0556 - acc: 0.9859\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 0s 501us/step - loss: 0.1083 - acc: 0.9648\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 0s 837us/step - loss: 0.1009 - acc: 0.9718\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.1150 - acc: 0.9683\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 0s 983us/step - loss: 0.0771 - acc: 0.9824\n",
      "142/142 [==============================] - 4s 28ms/step\n",
      "284/284 [==============================] - 0s 313us/step\n",
      "[CV]  activation=relu, batch_size=8, dropout_rate=0.0, epochs=50, optimizer=SGD, score=0.9577464788732394, total=  31.2s\n",
      "[CV] activation=relu, batch_size=8, dropout_rate=0.0, epochs=50, optimizer=SGD \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   59.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=8, epochs =10)\n",
    "\n",
    "input_dim= [X_train.shape[1]]\n",
    "activation =  ['relu', 'tanh', 'sigmoid'] \n",
    "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "dropout_rate = [0.0, 0.1, 0.5]\n",
    "#weight_constraint=[1, 2, 3, 4, 5]\n",
    "neurons = [5, 10, 20, 30, 40 ,50]\n",
    "init = ['uniform', 'lecun_uniform', 'normal']\n",
    "optimizer = [ 'SGD', 'adam']\n",
    "#optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "epochs = [50] \n",
    "batch_size = [8, 16, 32] \n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size,optimizer = optimizer, dropout_rate = dropout_rate,activation = activation)\n",
    "##############################################################\n",
    "grid = GridSearchCV(estimator=model, param_grid = param_grid,verbose=3)\n",
    "grid_result = grid.fit(X_train, y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
