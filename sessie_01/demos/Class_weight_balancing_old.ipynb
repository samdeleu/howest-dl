{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weight balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Import Keras libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                      0.0                      0.0   ...     \n",
       "1                      0.0                      0.0   ...     \n",
       "2                      0.0                      0.0   ...     \n",
       "3                      0.0                      0.0   ...     \n",
       "4                      0.0                      0.0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read customer satisfaction dataset\n",
    "\n",
    "dataset = pd.read_csv('./customersatisfaction.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wouter/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:19: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/wouter/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:20: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Remove the ID column\n",
    "\n",
    "dataset.drop('ID',axis=1,inplace=True)\n",
    "\n",
    "# Split features and targets\n",
    "\n",
    "y = dataset.TARGET.values\n",
    "X = dataset.drop('TARGET',axis=1)\n",
    "\n",
    "# Create training set and test set (1000 samples)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 10000, random_state =0)\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52816 samples, validate on 13204 samples\n",
      "Epoch 1/5\n",
      "52816/52816 [==============================] - 7s 139us/step - loss: 0.1754 - val_loss: 0.1495\n",
      "Epoch 2/5\n",
      "52816/52816 [==============================] - 7s 132us/step - loss: 0.1440 - val_loss: 0.1439\n",
      "Epoch 3/5\n",
      "52816/52816 [==============================] - 7s 135us/step - loss: 0.1406 - val_loss: 0.1430\n",
      "Epoch 4/5\n",
      "52816/52816 [==============================] - 7s 136us/step - loss: 0.1391 - val_loss: 0.1419\n",
      "Epoch 5/5\n",
      "52816/52816 [==============================] - 7s 130us/step - loss: 0.1379 - val_loss: 0.1413\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "\n",
    "y_train_one_hot = np_utils.to_categorical(y_train)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=input_dim, kernel_initializer=\"RandomUniform\",activation=\"relu\"))\n",
    "model.add(Dense(5, kernel_initializer=\"RandomUniform\",activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer=\"RandomUniform\",activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=adam)\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot, validation_split=0.2, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      9572\n",
      "           1       0.00      0.00      0.00       428\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.48      0.50      0.49     10000\n",
      "weighted avg       0.92      0.96      0.94     10000\n",
      "\n",
      "[[9572    0]\n",
      " [ 428    0]]\n",
      "95.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count klasse 0:  73012\n",
      "count klasse 1:  3008\n",
      "ratio:  24.272606382978722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f6b34641668>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# balancedness of the dataset\n",
    "label_count = np.bincount(y)\n",
    "\n",
    "print('count klasse 0: ',label_count[0])\n",
    "print('count klasse 1: ',label_count[1])\n",
    "\n",
    "print('ratio: ',label_count[0]/label_count[1])\n",
    "\n",
    "\n",
    "sns.catplot(x='TARGET',kind='count', data=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52033417 12.79457364]\n",
      "Train on 52816 samples, validate on 13204 samples\n",
      "Epoch 1/15\n",
      "52816/52816 [==============================] - 6s 121us/step - loss: 0.7137 - val_loss: 0.6722\n",
      "Epoch 2/15\n",
      "52816/52816 [==============================] - 7s 140us/step - loss: 0.6554 - val_loss: 0.6577\n",
      "Epoch 3/15\n",
      "52816/52816 [==============================] - 8s 147us/step - loss: 0.6444 - val_loss: 0.6558\n",
      "Epoch 4/15\n",
      "52816/52816 [==============================] - 8s 145us/step - loss: 0.6375 - val_loss: 0.6468\n",
      "Epoch 5/15\n",
      "52816/52816 [==============================] - 6s 118us/step - loss: 0.6306 - val_loss: 0.6457\n",
      "Epoch 6/15\n",
      "52816/52816 [==============================] - 7s 126us/step - loss: 0.6227 - val_loss: 0.6370\n",
      "Epoch 7/15\n",
      "52816/52816 [==============================] - 3s 57us/step - loss: 0.6156 - val_loss: 0.6411\n",
      "Epoch 8/15\n",
      "52816/52816 [==============================] - 5s 103us/step - loss: 0.6108 - val_loss: 0.6331\n",
      "Epoch 9/15\n",
      "52816/52816 [==============================] - 7s 128us/step - loss: 0.6062 - val_loss: 0.6397\n",
      "Epoch 10/15\n",
      "52816/52816 [==============================] - 3s 55us/step - loss: 0.6030 - val_loss: 0.6289\n",
      "Epoch 11/15\n",
      "52816/52816 [==============================] - 5s 87us/step - loss: 0.6026 - val_loss: 0.6302\n",
      "Epoch 12/15\n",
      "52816/52816 [==============================] - 6s 118us/step - loss: 0.5997 - val_loss: 0.6369\n",
      "Epoch 13/15\n",
      "52816/52816 [==============================] - 7s 127us/step - loss: 0.5976 - val_loss: 0.6297\n",
      "Epoch 14/15\n",
      "52816/52816 [==============================] - 6s 105us/step - loss: 0.5959 - val_loss: 0.6359\n",
      "Epoch 15/15\n",
      " 3392/52816 [>.............................] - ETA: 1s - loss: 0.6162"
     ]
    }
   ],
   "source": [
    "# Train a neural network with balanced class weights \n",
    "\n",
    "y_train_one_hot = np_utils.to_categorical(y_train)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=input_dim, kernel_initializer=\"RandomUniform\",activation=\"relu\"))\n",
    "model.add(Dense(5, kernel_initializer=\"RandomUniform\",activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer=\"RandomUniform\",activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=adam)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "print(class_weights)\n",
    "class_weights= dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "#history = model.fit(X_train, y_train_one_hot, validation_split=0.2, epochs=epochs, verbose=1,class_weight=class_weights)\n",
    "history = model.fit(X_train, y_train_one_hot, validation_split=0.2, epochs=epochs, verbose=1,class_weight={0:1,1:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      9572\n",
      "           1       0.17      0.54      0.26       428\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.58      0.71      0.60     10000\n",
      "weighted avg       0.94      0.87      0.90     10000\n",
      "\n",
      "[[8467 1105]\n",
      " [ 196  232]]\n",
      "86.99\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52033417 12.79457364]\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
